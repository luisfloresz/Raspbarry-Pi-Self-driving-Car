{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector de carriles con en pista de atletismo Raspberry Pi \n",
    "\n",
    "\n",
    "Elaborado por: Luis Felipe Flores Zertuche   \n",
    "Matrícula: 523197  \n",
    "Carrera: ITR  \n",
    "Fecha: 2019-05-23  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción\n",
    "\n",
    "Este proyecto consta de un carro controlado por una Raspberry Pi 3 B+ y que maneja de forma autonoma en una pista de atletismo. De hardware utiliza una Raspberry Camera v2 para la deteccion de lineas y un puente H para controlar los 4 motores y de software utiliza python3 junto con OpenCv para el procesamiento de imagenes.\n",
    "\n",
    "A continuacion se explicara paso a paso como realizar este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivos \n",
    "\n",
    "* Diseñar y armar el carro con todos sus componentes.\n",
    "\n",
    "* Controlar el carro con un control o teclado para que se mueve y utilice la camara.\n",
    "\n",
    "* Realizar un video de la pista grabado del carro para poder realizar la deteccion de lineas en un video.\n",
    "\n",
    "* Crear un algoritmo de control para que el carro detecte el centro del carril en el video.\n",
    "\n",
    "* Conducir en la pista de atletismo de manera autonoma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Instalar sistema operativo (Raspbian).\n",
    "- Instalar librerías (open cv, RPi.GPIO, picamera).\n",
    "- Recoleccion de datos de la pista de atletismo (Fotos y videos).\n",
    "- Filtrado y obtencion de bordes.\n",
    "- Obtener hough lines en una imagen.\n",
    "- Metodo para el control autonomo del carro.\n",
    "- Simulacion de metodo de control con un video.\n",
    "- Lograr el movimiento autonomo en tiempo real del vehiculo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instalar Sistema Operativo\n",
    "\n",
    "Raspbian es el sistema operativo oficial de Raspberry Pi.\n",
    "\n",
    "El enlace oficial para descargar Raspbian:\n",
    "https://www.raspberrypi.org/downloads/raspbian/\n",
    "\n",
    "Para instalarlo seguir esta guia de instalacion:\n",
    "https://www.raspberrypi.org/documentation/installation/installing-images/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instalar librerías\n",
    "\n",
    "Las librerias principales que utilizamos en este proyecto son:\n",
    "- OpenCv: Para el procesamiento de imagenes.\n",
    "- RPI.GPIO: Para el control de las entradas y salidas (Motores).\n",
    "- picamera: Para utilizar la Raspberry Camera.\n",
    "- time: Para poder utilizar delays y calcular el tiempo que tarda en correr.\n",
    "- math y numpy: Para realizar operaciones matematicas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recoleccion de datos de la pista de atletismo (Fotos y videos)\n",
    "\n",
    "Para poder empezar a filtrar y encontrar lineas en una imagen, primero tenemos que tener la imagen y para eso se crea el un programa para controlar el carro y tomar fotos y videos desde el teclado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raspberry Controled car  \n",
      " Control the car with arrow keys \n",
      "\n",
      "Enter = Stop \n",
      " f = Take photo \n",
      " v = Start recording \n",
      " s = Stop recording\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Raspberry Controled car\n",
    "\n",
    "    Control the car with arrow keys,\n",
    "    Enter = Stop\n",
    "    f = Take photo\n",
    "    v = Start recording\n",
    "    s = Stop recording\n",
    "\n",
    "    Luis Felipe Flores Zertuche\n",
    "    Universidad de Monterrey\n",
    "\"\"\"\n",
    "\n",
    "import RPi.GPIO as GPIO\n",
    "import time\n",
    "import curses\n",
    "import picamera\n",
    "from datetime import datetime\n",
    "\n",
    "print('Raspberry Controled car ','\\n','Control the car with arrow keys','\\n')\n",
    "print('Enter = Stop','\\n','f = Take photo','\\n','v = Start recording','\\n','s = Stop recording')\n",
    "\n",
    "# Create a time object, datetime.now() = date & time with microseconds\n",
    "#time = datetime.now()\n",
    "\n",
    "# Create a camera object from picamera\n",
    "camera = picamera.PiCamera()\n",
    "camera.resolution = (640,360)      # 1/3 of max resolution\n",
    "camera.framerate = 20\n",
    "\n",
    "# Get the curses window, turn off echoing of keyboard to screen, turn on\n",
    "# instant (no waiting) key response, and use special values for cursor keys\n",
    "screen = curses.initscr()\n",
    "curses.noecho() \n",
    "curses.cbreak()\n",
    "screen.keypad(True)\n",
    "\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "\n",
    "motorLeftF = 5          # GPIO 5, move left wheels foward, IN1\n",
    "motorLeftR = 6          # GPIO 6, move left wheels backward, IN2\n",
    "\n",
    "motorRightF = 19        # GPIO 13, move right wheels foward, IN3\n",
    "motorRightR = 13        # GPIO 19, move right wheels backward, IN4\n",
    "\n",
    "\n",
    "GPIO.setup(motorLeftF, GPIO.OUT)\n",
    "GPIO.setup(motorLeftR, GPIO.OUT)\n",
    "GPIO.setup(motorRightF, GPIO.OUT)\n",
    "GPIO.setup(motorRightR, GPIO.OUT)\n",
    "\n",
    "def moveFoward():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.HIGH)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.HIGH)\n",
    "\n",
    "def moveBackward():\n",
    "    GPIO.output(motorLeftF, GPIO.HIGH)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.HIGH)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "def rotateRight():\n",
    "    GPIO.output(motorLeftF, GPIO.HIGH)\n",
    "    GPIO.output(motorLeftR, GPIO.HIGH)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.HIGH)\n",
    "\n",
    "def rotateLeft():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.HIGH)\n",
    "    GPIO.output(motorRightF, GPIO.HIGH)\n",
    "    GPIO.output(motorRightR, GPIO.HIGH)\n",
    "\n",
    "def rotateBLeft():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.HIGH)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "def rotateBRight():\n",
    "    GPIO.output(motorLeftF, GPIO.HIGH)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "def carStop():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "try:\n",
    "        while True:   \n",
    "            char = screen.getch()\n",
    "            if char == ord('q'):\n",
    "                break\n",
    "            elif char == curses.KEY_UP:\n",
    "                moveFoward()\n",
    "            elif char == curses.KEY_DOWN:\n",
    "                moveBackward()\n",
    "            elif char == curses.KEY_RIGHT:\n",
    "                rotateRight()\n",
    "            elif char == curses.KEY_LEFT:\n",
    "                rotateLeft()\n",
    "            elif char == 10:\n",
    "                carStop()\n",
    "            elif char == ord('k'):\n",
    "                rotateBRight()\n",
    "            elif char == ord('l'):\n",
    "                rotateBLeft()\n",
    "            elif char == ord('f'):\n",
    "                camera.capture(str(datetime.now())+'.jpg')\n",
    "                print('Snapshot saved')\n",
    "            elif char == ord('v'):\n",
    "                camera.start_recording(str(datetime.now()) +'.h264')\n",
    "                print('Start recording, press S to stop')\n",
    "            elif char == ord('s'):\n",
    "                camera.stop_recording()\n",
    "                print('Video saved')\n",
    "             \n",
    "finally:\n",
    "    #Close down curses properly, inc turn echo back on!\n",
    "    curses.nocbreak(); screen.keypad(0); curses.echo()\n",
    "    curses.endwin()\n",
    "\n",
    "GPIO.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtrado y obtencion de bordes\n",
    "\n",
    "Para que el programa detecte los bordes correctamente, la imagen tiene que pasar por tres filtros.\n",
    "\n",
    "\n",
    "- cv2.cvtColor(img, cv2.COLOR_RGB2GRAY): Transforma la imagen a escala de grises.\n",
    "- cv2.GaussianBlur(img_grey, kernel_size, sigmaX=0, sigmaY=0): Difumina la imagen.\n",
    "- cv2.Canny(img_blur, low_threshold, high_threshold, apertureSize=3): Obtiene los bordes.\n",
    "\n",
    "La pista de atletismo tiene muchas piedritas las cuales crean ruido a la hora de sacar los bordes (se ven bordes por todas partes). Para resolver esto aumente el kernel filtro Gaussian Blur para difuminar las piedras sin perder los bordes que nos interesan (los carriles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Filter and edge detection\n",
    "\n",
    "    Luis Felipe Flores Zertuche\n",
    "    Universidad de Monterrey\n",
    "\"\"\"\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "\n",
    "# run line detection pipeline\n",
    "def run_pipeline(img_name):\n",
    "\n",
    "\n",
    "    # 1.- Read image\n",
    "    img_colour = cv2.imread(img_name)\n",
    "\n",
    "    # verify that image `img` exist\n",
    "    if img_colour is None:\n",
    "        print('ERROR: image ', img_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "    # 2. Convert from BGR to RGB then from RGB to greyscale\n",
    "    img_colour_rgb = cv2.cvtColor(img_colour, cv2.COLOR_BGR2RGB)\n",
    "    gray = cv2.cvtColor(img_colour_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # 3.- Apply Gaussuan smoothing\n",
    "    kernel_size = (21,21)\n",
    "    blur_gray = cv2.GaussianBlur(gray, kernel_size, sigmaX=0, sigmaY=0)\n",
    "\n",
    "    #blur = cv2.bilateralFilter(grey, 21, 0, 0)\n",
    "\n",
    "    # 4.- Apply Canny edge detector\n",
    "    low_threshold = 60\n",
    "    high_threshold = 80\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold, apertureSize=3)\n",
    "\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.imshow(gray, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(2)\n",
    "    plt.imshow(blur_gray, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure(3)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "# Run pipeline\n",
    "img_name = 'pista.jpg'\n",
    "run_pipeline(img_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtener Hough lines en una imagen\n",
    "\n",
    "Es mucho mas sencillo analizar una imagen que un video, por eso empezamos obteniendo las lineas de Hough en una imagen. Asi podemos verificar si los resultados obtenidos son los deseados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Line detection in an img using Hough lines\n",
    "\n",
    "    Luis Felipe Flores Zertuche\n",
    "    Universidad de Monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# select a region of interest\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "\n",
    "# run line detection pipeline\n",
    "def run_pipeline(img_name):\n",
    "\n",
    "\n",
    "    # 1.- Read image\n",
    "    img_colour = cv2.imread(img_name)\n",
    "\n",
    "    # verify that image `img` exist\n",
    "    if img_colour is None:\n",
    "        print('ERROR: image ', img_name, 'could not be read')\n",
    "        exit()\n",
    "\n",
    "    # 2. Convert from BGR to RGB then from RGB to greyscale\n",
    "    img_colour_rgb = cv2.cvtColor(img_colour, cv2.COLOR_BGR2RGB)\n",
    "    grey = cv2.cvtColor(img_colour_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # 3.- Apply Gaussuan smoothing\n",
    "    kernel_size = (21,21)\n",
    "    blur_grey = cv2.GaussianBlur(grey, kernel_size, sigmaX=0, sigmaY=0)\n",
    "\n",
    "    # 4.- Apply Canny edge detector\n",
    "    low_threshold = 60\n",
    "    high_threshold = 80\n",
    "    edges = cv2.Canny(blur_grey, low_threshold, high_threshold, apertureSize=3)\n",
    "\n",
    "    # 5.- Define a polygon-shape like region of interest\n",
    "    img_shape = grey.shape\n",
    "\n",
    "\n",
    "    # Region of interest\n",
    "    bottom_left = (0, 350)\n",
    "    top_left = (0, 80)\n",
    "    top_right = (1280, 80)\n",
    "    bottom_right = (1280, 350)\n",
    "\n",
    "    # create a vertices array that will be used for the roi\n",
    "    vertices = np.array([[bottom_left,top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "\n",
    "    # 6.- Get a region of interest using the just created polygon. This will be\n",
    "    #     used together with the Hough transform to obtain the estimated Hough lines\n",
    "    masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "    # 7.- Apply Hough transform for lane lines detection\n",
    "    rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "    threshold = 10                # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_len = 5              # minimum number of pixels making up a line\n",
    "    max_line_gap = 10              # maximum gap in pixels between connectable line segments\n",
    "    line_image = np.copy(img_colour)*0   # creating a blank to draw lines on\n",
    "    hough_lines = cv2.HoughLinesP(masked_edges, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "\n",
    "    # 8.- Visualise input and output images\n",
    "    img_colour_with_lines = img_colour_rgb.copy()\n",
    "##    if(hough_lines !=None):\n",
    "##        for line in hough_lines:\n",
    "##            for x1, y1, x2, y2 in line:\n",
    "##                cv2.line(img_colour_with_lines, (x1, y1), (x2, y2), (0,0,255), 3)\n",
    "##                slope = (y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "##                print(slope)\n",
    "\n",
    "    # 9.- Define left and right lane\n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "\n",
    "    if(hough_lines != []):\n",
    "        for line in hough_lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                cv2.line(img_colour_with_lines, (x1, y1), (x2, y2), (0,0,255), 3)\n",
    "                slope = float(y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "                #print(slope)\n",
    "                # if math.fabs(slope) < 0.5: # <-- Only consider extreme slope\n",
    "                #     continue\n",
    "                if slope <= 0: # <-- If the slope is negative, left group.\n",
    "                    left_line_x.extend([x1, x2])\n",
    "                    left_line_y.extend([y1, y2])\n",
    "                else: # <-- Otherwise, right group.\n",
    "                    right_line_x.extend([x1, x2])\n",
    "                    right_line_y.extend([y1, y2])\n",
    "\n",
    "    min_y = 0 # <-- Just below the horizon\n",
    "    max_y = 230 # <-- The bottom of the image\n",
    "\n",
    "\n",
    "    poly_left = np.poly1d(np.polyfit(\n",
    "    left_line_y,\n",
    "    left_line_x,\n",
    "    deg=1\n",
    "    ))\n",
    "\n",
    "    left_x_start = int(poly_left(max_y))\n",
    "    left_x_end = int(poly_left(min_y))\n",
    "\n",
    "    poly_right = np.poly1d(np.polyfit(\n",
    "    right_line_y,\n",
    "    right_line_x,\n",
    "    deg=1\n",
    "    ))\n",
    "\n",
    "    right_x_start = int(poly_right(max_y))\n",
    "    right_x_end = int(poly_right(min_y))\n",
    "\n",
    "    fullline = [[\n",
    "                [left_x_start, max_y, left_x_end, min_y],\n",
    "                [right_x_start, max_y, right_x_end, min_y],\n",
    "                ]]\n",
    "    \n",
    "    #print(fullline)\n",
    "\n",
    "    img_colour_with_fulllines = img_colour_rgb.copy()    \n",
    "    for line in fullline:\n",
    "    \tfor x1, y1, x2, y2 in line:\n",
    "    \t\tcv2.line(img_colour_with_fulllines, (x1, y1), (x2, y2), (0,255,0), 3)\n",
    "\n",
    "    pf_bottom_left = (left_x_end , min_y)\n",
    "    pf_top_left = (left_x_start, max_y)\n",
    "    pf_top_right = (right_x_start, max_y)\n",
    "    pf_bottom_right = (right_x_end, min_y)\n",
    "\n",
    "    pf_vertices = np.array([[pf_bottom_left,pf_top_left, pf_top_right, pf_bottom_right]], dtype=np.int32)\n",
    "    cv2.fillPoly(img_colour_with_fulllines, pf_vertices, (255,0,0))\n",
    "\n",
    "\n",
    "    # visualise input and output images\n",
    "##    plt.figure(1)\n",
    "##    plt.imshow(masked_edges)\n",
    "##    plt.axis('off')\n",
    "##\n",
    "##    plt.figure(2)\n",
    "##    plt.imshow(blur_grey, cmap='gray')\n",
    "##    plt.axis('off')\n",
    "##\n",
    "##    plt.figure(3)\n",
    "##    plt.imshow(edges, cmap='gray')  \n",
    "##    plt.axis('off')\n",
    "\n",
    "##    plt.figure(4)\n",
    "##    plt.imshow(img_colour_with_lines)\n",
    "##    plt.axis('off')\n",
    "\n",
    "    plt.figure(5)\n",
    "    plt.imshow(img_colour_with_fulllines, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    #print (hough_lines)\n",
    "    print(max(left_line_y))\n",
    "    print(max(right_line_y))\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "# Run pipeline\n",
    "img_name = 'pista.jpg'\n",
    "run_pipeline(img_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metodo para el control autonomo del carro\n",
    "\n",
    "Esta parte fue todo un reto ya que la pista de atletismo esta muy grande para el carro. Los carriles estan separados por 1.22 metros, como la camara no tiene mucha altura los carriles que detecta estan aproximadamente a 1 metro. \n",
    "El primer metodo que intente fue encontrar el centro de la imagen y compararlo con el centro de las Hough lines, pero al analizar varios videos que grabe me di cuenta que no siempre detectaba la linea hasta el final. Esto me puede crear un error al decidir a que direccion ir. \n",
    "\n",
    "Por esa razon tuve que buscar otra manera de hacerlo. Al detectar las Hough lines en el video me di cuenta que casi siempre se detecta bien el punto inferior de las lineas por lo que opte en usar los putos inferiores de ambas lineas y encontrar el valor minimo de y de ambas. Si los valores son iguales el carro va centrado y si uno es mayor que el otro es que se esta moviendose hacia un lado.\n",
    "\n",
    "Para enontrar los valores minimos de las Hough lines utilice la funcion max(<carril a analizar>), se utiliza el maximo porque los pixeles en y van de arriba hacia abajo. Ya teniendo ambos valores los compare y con el resultado decido en que direccion ir. Para que no este cambiando de sentido constantemente le agregue una tolerancia de 20 pixeles a cada lado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Simulacion del metodo de control con un video\n",
    "\n",
    "Antes de probarlo en tiempo real, realice una simulacion con un video de la pista de atletismo que grabe con el carro en la parte de obtencion de datos. Encuentro los fps a los que corre el video de salida y la direccion que debe tomar el carro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tLine detection using Hough lines\n",
    "\n",
    "\tLuis Felipe Flores\n",
    "\tUniversidad de Monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# select a region of interest\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "\n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "\n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color\n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "\n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "\n",
    "\n",
    "# run line detection pipeline\n",
    "def run_pipeline():\n",
    "\n",
    "    # initialise a video capture object\n",
    "    cap = cv2.VideoCapture(\"Video_Pista2.h264\")\n",
    "\n",
    "    # check that the videocapture object was successfully created\n",
    "    if(not cap.isOpened()):\n",
    "        print(\"Error opening video source\")\n",
    "        exit()\n",
    "    \n",
    "    # create new windows for visualisation purposes\n",
    "    cv2.namedWindow('input video', cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "    while (cap.isOpened):\n",
    "        \n",
    "        flagstart = time.time()\n",
    "        \n",
    "        # grab current frame\n",
    "        ret, frame = cap.read()        \n",
    "\n",
    "        # verify that frame was properly captured\n",
    "        if ret == False:\n",
    "            print(\"ERROR: current frame could not be read\")            \n",
    "            break\n",
    "\n",
    "        # 1.- Read image\n",
    "        #frame_rs = cv2.resize(frame,(640,360))\n",
    "        img_colour = frame\n",
    "\n",
    "\n",
    "        # verify that image `img` exist\n",
    "        if img_colour is None:\n",
    "            print('ERROR: image ', img_name, 'could not be read')\n",
    "            exit()\n",
    "\n",
    "        # 2. Convert from BGR to RGB then from RGB to greyscale\n",
    "        img_colour_rgb = img_colour\n",
    "        grey = cv2.cvtColor(img_colour_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # 3.- Apply Gaussuan smoothing\n",
    "        kernel_size = (21,21)\n",
    "        blur_grey = cv2.GaussianBlur(grey, kernel_size, sigmaX=0, sigmaY=0)\n",
    "\n",
    "        # 4.- Apply Canny edge detector\n",
    "        low_threshold = 60\n",
    "        high_threshold = 80\n",
    "        edges = cv2.Canny(blur_grey, low_threshold, high_threshold, apertureSize=3)\n",
    "\n",
    "        # 5.- Define a polygon-shape like region of interest\n",
    "        img_shape = grey.shape\n",
    "\n",
    "\n",
    "        # Region of interest\n",
    "        bottom_left = (0, 175)\n",
    "        top_left = (0, 40)\n",
    "        top_right = (640, 40)\n",
    "        bottom_right = (640, 175)\n",
    "        \n",
    "\n",
    "        # create a vertices array that will be used for the roi\n",
    "        vertices = np.array([[bottom_left,top_left, top_right, bottom_right]], dtype=np.int32)\n",
    "        \n",
    "\n",
    "        # 6.- Get a region of interest using the just created polygon. This will be\n",
    "        #     used together with the Hough transform to obtain the estimated Hough lines\n",
    "        masked_edges = region_of_interest(edges, vertices)\n",
    "\n",
    "        # 7.- Apply Hough transform for lane lines detection\n",
    "        rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "        threshold = 10                # minimum number of votes (intersections in Hough grid cell)\n",
    "        min_line_len = 5              # minimum number of pixels making up a line\n",
    "        max_line_gap = 10              # maximum gap in pixels between connectable line segments\n",
    "        line_image = np.copy(img_colour)*0   # creating a blank to draw lines on\n",
    "        hough_lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "\n",
    "        # 8.- Visualise input and output images\n",
    "        img_colour_with_lines = img_colour_rgb.copy()\n",
    "\n",
    "        # 9.- Define left and right lane\n",
    "        left_line_x = []\n",
    "        left_line_y = []\n",
    "        right_line_x = []\n",
    "        right_line_y = []\n",
    "\n",
    "        if(hough_lines !=None):\n",
    "            for line in hough_lines:\n",
    "                for x1, y1, x2, y2 in line:\n",
    "                    cv2.line(img_colour_with_lines, (x1, y1), (x2, y2), (0,0,255), 3)\n",
    "                    slope = float(y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "                    #print(slope)\n",
    "                    if math.fabs(slope) < 0.3: # <-- Only consider extreme slope\n",
    "                        continue\n",
    "                    if slope <= 0: # <-- If the slope is negative, left group.\n",
    "                        left_line_x.extend([x1, x2])\n",
    "                        left_line_y.extend([y1, y2])\n",
    "                    else: # <-- Otherwise, right group.\n",
    "                        right_line_x.extend([x1, x2])\n",
    "                        right_line_y.extend([y1, y2])\n",
    "\n",
    "        min_y = 0 # <-- Just below the horizon\n",
    "        #max_y = 350 # <-- The bottom of the image\n",
    "        max_y = 175\n",
    "        \n",
    "\n",
    "        if(left_line_y != [] and left_line_x != []):\n",
    "            poly_left = np.poly1d(np.polyfit(\n",
    "                left_line_y,\n",
    "                left_line_x,\n",
    "                deg=1\n",
    "                ))\n",
    "\n",
    "        left_x_start = int(poly_left(max_y))\n",
    "        left_x_end = int(poly_left(min_y))\n",
    "\n",
    "        if(right_line_y != [] and right_line_x != []):\n",
    "            poly_right = np.poly1d(np.polyfit(\n",
    "                right_line_y,\n",
    "                right_line_x,\n",
    "                deg=1\n",
    "                ))\n",
    "            right_x_start = int(poly_right(max_y))\n",
    "            right_x_end = int(poly_right(min_y))\n",
    "\n",
    "        fullline = [[\n",
    "                    [left_x_start, max_y, left_x_end, min_y],\n",
    "                    [right_x_start, max_y, right_x_end, min_y],\n",
    "                    ]]\n",
    "        \n",
    "        #print(fullline)\n",
    "\n",
    "        img_colour_with_fulllines = img_colour_rgb.copy()    \n",
    "        for line in fullline:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                    cv2.line(img_colour_with_fulllines, (x1, y1), (x2, y2), (0,255,0), 3)\n",
    "\n",
    "\n",
    "        flagend = time.time()\n",
    "        #print(' Run time: ')\n",
    "        runTime = flagend - flagstart\n",
    "        fps = 1/runTime\n",
    "        #print(runTime)\n",
    "        #print(' Fps: ')\n",
    "        #print(fps)\n",
    "        Fps = 'Fps = ' + str(fps)\n",
    "\n",
    "        # Add FPS to img\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_colour_with_fulllines,Fps,(0,20), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "        # Calculate min left and right point in y\n",
    "        if(left_line_y !=[] and right_line_y !=[]):\n",
    "            left_min = max(left_line_y)\n",
    "            right_min = max(right_line_y)\n",
    "##          print(left_min)\n",
    "##          print(right_min)\n",
    "            direction = 'left = ' + str(left_min) + ' Right = ' + str(right_min)\n",
    "            #print(direction)\n",
    "\n",
    "            if (left_min > (right_min + 20)):\n",
    "                motor = 'right'\n",
    "                #rotateRight()\n",
    "                #time.sleep(0.1)\n",
    "                #moveFoward()\n",
    "            elif(right_min > (left_min + 20)):\n",
    "                motor = 'left'\n",
    "                #rotateLeft()\n",
    "                #time.sleep(0.1)\n",
    "                #moveFoward()\n",
    "            else:\n",
    "                #moveFoward()\n",
    "                motor = 'foward'\n",
    "            #print(motor)\n",
    "\n",
    "            cv2.putText(img_colour_with_fulllines,motor,(0,60), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        #visualise current frame\n",
    "        cv2.imshow('input video',img_colour_with_fulllines)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            cv2.imwrite('carriles.png', img_colour_with_fulllines)\n",
    "            cv2.imwrite('carriles_segmentados.png', img_colour_with_fulllines)\n",
    "            break\n",
    "\n",
    "           \n",
    "    return None\n",
    "\n",
    "# Run pipeline\n",
    "run_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Movimiento autonomo del vehiculo\n",
    "\n",
    "Para lograr esto simplemente hay que combinar el codigo del contol de motores y el acceso a la Raspberrry camera con  programa anterior de la simulacion detector de lineas y asi logramos el movimiento autonomo en tiempo real del vehiculo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\tSelf driving car using Raspberry Pi\n",
    "\n",
    "\tLuis Felipe Flores\n",
    "\tUniversidad de Monterrey\n",
    "\"\"\"\n",
    "\n",
    "# import the necessary packages\n",
    "from picamera.array import PiRGBArray\n",
    "from picamera import PiCamera\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import RPi.GPIO as GPIO\n",
    "import math\n",
    " \n",
    "# initialize the camera and grab a reference to the raw camera capture\n",
    "camera = PiCamera()\n",
    "camera.resolution = (640, 360)\n",
    "camera.framerate = 20\n",
    "rawCapture = PiRGBArray(camera, size=(640, 360))\n",
    " \n",
    "# allow the camera to warmup\n",
    "time.sleep(0.1)\n",
    "\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "\n",
    "motorLeftF = 5          # GPIO 5, move left wheels foward, IN1\n",
    "motorLeftR = 6          # GPIO 6, move left wheels backward, IN2\n",
    "\n",
    "motorRightF = 19        # GPIO 13, move right wheels foward, IN3\n",
    "motorRightR = 13        # GPIO 19, move right wheels backward, IN4\n",
    "\n",
    "GPIO.setwarnings(False)\n",
    "\n",
    "GPIO.setup(motorLeftF, GPIO.OUT)\n",
    "GPIO.setup(motorLeftR, GPIO.OUT)\n",
    "GPIO.setup(motorRightF, GPIO.OUT)\n",
    "GPIO.setup(motorRightR, GPIO.OUT)\n",
    "\n",
    "def moveFoward():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.HIGH)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.HIGH)\n",
    "\n",
    "def moveBackward():\n",
    "    GPIO.output(motorLeftF, GPIO.HIGH)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.HIGH)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "def rotateRight():\n",
    "    GPIO.output(motorLeftF, GPIO.HIGH)\n",
    "    GPIO.output(motorLeftR, GPIO.HIGH)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.HIGH)\n",
    "\n",
    "def rotateLeft():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.HIGH)\n",
    "    GPIO.output(motorRightF, GPIO.HIGH)\n",
    "    GPIO.output(motorRightR, GPIO.HIGH)\n",
    "\n",
    "def rotateBLeft():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.HIGH)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "def rotateBRight():\n",
    "    GPIO.output(motorLeftF, GPIO.HIGH)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "\n",
    "def carStop():\n",
    "    GPIO.output(motorLeftF, GPIO.LOW)\n",
    "    GPIO.output(motorLeftR, GPIO.LOW)\n",
    "    GPIO.output(motorRightF, GPIO.LOW)\n",
    "    GPIO.output(motorRightR, GPIO.LOW)\n",
    "    \n",
    "# capture frames from the camera\n",
    "for frame in camera.capture_continuous(rawCapture, format=\"bgr\", use_video_port=True):\n",
    "\t# grab the raw NumPy array representing the image, then initialize the timestamp\n",
    "\t# and occupied/unoccupied text\n",
    "        flagstart = time.time()\n",
    "\t\n",
    "        image = frame.array\n",
    "\t\n",
    "\t# 1.- Read image\n",
    "        #frame_rs = cv2.resize(frame,(640,360))\n",
    "        img_colour = image\n",
    "\n",
    "\n",
    "        # verify that image `img` exist\n",
    "        if img_colour is None:\n",
    "            print('ERROR: image ', img_name, 'could not be read')\n",
    "            exit()\n",
    "\n",
    "        # 2. Convert from BGR to RGB then from RGB to greyscale\n",
    "        img_colour_rgb = img_colour\n",
    "        grey = cv2.cvtColor(img_colour_rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # 3.- Apply Gaussuan smoothing\n",
    "        kernel_size = (21,21)\n",
    "        blur_grey = cv2.GaussianBlur(grey, kernel_size, sigmaX=0, sigmaY=0)\n",
    "\n",
    "        # 4.- Apply Canny edge detector\n",
    "        low_threshold = 60\n",
    "        high_threshold = 80\n",
    "        edges = cv2.Canny(blur_grey, low_threshold, high_threshold, apertureSize=3)\n",
    "\n",
    "        # 5.- Define a polygon-shape like region of interest\n",
    "        img_shape = grey.shape\n",
    "\n",
    "        # 6.- Apply Hough transform for lane lines detection\n",
    "        rho = 1                       # distance resolution in pixels of the Hough grid\n",
    "        theta = np.pi/180             # angular resolution in radians of the Hough grid\n",
    "        threshold = 10                # minimum number of votes (intersections in Hough grid cell)\n",
    "        min_line_len = 5              # minimum number of pixels making up a line\n",
    "        max_line_gap = 10              # maximum gap in pixels between connectable line segments\n",
    "        line_image = np.copy(img_colour)*0   # creating a blank to draw lines on\n",
    "        hough_lines = cv2.HoughLinesP(edges, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "\n",
    "        # 7.- Visualise input and output images\n",
    "        img_colour_with_lines = img_colour_rgb.copy()\n",
    "\n",
    "        # 8.- Define left and right lane\n",
    "        left_line_x = []\n",
    "        left_line_y = []\n",
    "        right_line_x = []\n",
    "        right_line_y = []\n",
    "\n",
    "        if(hough_lines !=None):\n",
    "            for line in hough_lines:\n",
    "                for x1, y1, x2, y2 in line:\n",
    "                    cv2.line(img_colour_with_lines, (x1, y1), (x2, y2), (0,0,255), 3)\n",
    "                    slope = float(y2 - y1) / (x2 - x1) # <-- Calculating the slope.\n",
    "                    #print(slope)\n",
    "                    if math.fabs(slope) < 0.2: # <-- Only consider extreme slope\n",
    "                        continue\n",
    "                    if slope <= 0: # <-- If the slope is negative, left group.\n",
    "                        left_line_x.extend([x1, x2])\n",
    "                        left_line_y.extend([y1, y2])\n",
    "                    else: # <-- Otherwise, right group.\n",
    "                        right_line_x.extend([x1, x2])\n",
    "                        right_line_y.extend([y1, y2])\n",
    "\n",
    "        min_y = 0\n",
    "        max_y = 175\n",
    "        \n",
    "\n",
    "        if(left_line_y != [] and left_line_x != []):\n",
    "            poly_left = np.poly1d(np.polyfit(\n",
    "                left_line_y,\n",
    "                left_line_x,\n",
    "                deg=1\n",
    "                ))\n",
    "            left_x_start = int(poly_left(max_y))\n",
    "            left_x_end = int(poly_left(min_y))\n",
    "\n",
    "        if(right_line_y != [] and right_line_x != []):\n",
    "            poly_right = np.poly1d(np.polyfit(\n",
    "                right_line_y,\n",
    "                right_line_x,\n",
    "                deg=1\n",
    "                ))\n",
    "            right_x_start = int(poly_right(max_y))\n",
    "            right_x_end = int(poly_right(min_y))\n",
    "            \n",
    "        img_colour_with_fulllines = img_colour_rgb.copy()\n",
    "        if (left_line_y != [] and left_line_x != [] and right_line_y != [] and right_line_x != []):\n",
    "            fullline = [[\n",
    "                        [left_x_start, max_y, left_x_end, min_y],\n",
    "                        [right_x_start, max_y, right_x_end, min_y],\n",
    "                        ]]\n",
    "            \n",
    "            #print(fullline)\n",
    "    \n",
    "            for line in fullline:\n",
    "                for x1, y1, x2, y2 in line:\n",
    "                        cv2.line(img_colour_with_fulllines, (x1, y1), (x2, y2), (0,255,0), 3)\n",
    "\n",
    "        \n",
    "\n",
    "        # Calculate min left and right point in y\n",
    "        if(left_line_y !=[] and right_line_y !=[]):\n",
    "            left_min = max(left_line_y)\n",
    "            right_min = max(right_line_y)\n",
    "##          print(left_min)\n",
    "##          print(right_min)\n",
    "            direction = 'left = ' + str(left_min) + ' Right = ' + str(right_min)\n",
    "            #print(direction)\n",
    "            \n",
    "            if (left_min > (right_min + 20)):\n",
    "                motor = 'right'\n",
    "                rotateRight()\n",
    "                time.sleep(0.1)\n",
    "                moveFoward()\n",
    "            elif(right_min > (left_min + 20)):\n",
    "                motor = 'left'\n",
    "                rotateLeft()\n",
    "                time.sleep(0.1)\n",
    "                moveFoward()\n",
    "            else:\n",
    "                moveFoward()\n",
    "                motor = 'foward'\n",
    "            #print(motor)\n",
    "\n",
    "            #cv2.putText(img_colour_with_fulllines,motor,(0,60), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        flagend = time.time()\n",
    "        #print(' Run time: ')\n",
    "        runTime = flagend - flagstart\n",
    "        fps = 1/runTime\n",
    "        #print(runTime)\n",
    "        #print(' Fps: ')\n",
    "        #print(fps)\n",
    "        Fps = 'Fps = ' + str(fps)\n",
    "\n",
    "        # Add FPS to img\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(img_colour_with_fulllines,Fps,(0,20), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "\n",
    "        #visualise current frame\n",
    "        cv2.imshow('input video',img_colour_with_fulllines)\n",
    "\n",
    "        # Display the resulting frame\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            #cv2.imwrite('carriles.png', img_colour_with_fulllines)\n",
    "            #cv2.imwrite('carriles_segmentados.png', img_colour_with_fulllines)\n",
    "            carStop()\n",
    "            break\n",
    " \n",
    "\t# clear the stream in preparation for the next frame\n",
    "        rawCapture.truncate(0)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Este proyecto no fue nada facil ya que es muy largo ycomplicado. Para poder realizarlo tuve que hacer parte por parte y todos los programas separados para poder entender que me da cada cosa y verificar si es el resultado es el que busco. Tuve que ser muy organizado a la hora de codificar para poder hacer todo por partes y al final juntarlo sin problemas. Utilice casi todo lo visto en el semestre para realizar este proyecto, lo cual me gusto mucho ya que termine entendiendo perfectamente lo que esta pasando en cada parte de mi programa. Uno de los retos principales fue que la pista estaba muy grande y los carriles muy separados para las dimensiones del carro, tuve que hacer varios videos con diferente angulo en la camara para decidir el angulo en que funciona mejor el programa. Otro reto fue que un dia antes cuando realize mi segunda prueba satisfactoria del carro se me descompuso el puente H, de suerte tenia otro de respuesto y lo pude cambiar.\n",
    "\n",
    "Este proyecto todavia tiene muchas areas de oportunidad, ya que actualmente no calcula la curvatura de la vuelta ni predice a donde girar. Tambien se le puede agregar una red neuronal para que maneje autonomamente con datos previamente capturados. Otra oportunidad es desplegar la camara en un servidor junto con un mapa y con la velocidad y aceleracion del vehiculo y permitir el control del carro desde el servidor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
